{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51620bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Write a python program which searches all the product under a particular product from www.amazon.in.\n",
    "#The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search\n",
    "#for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c519fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import all required Libraries\n",
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from getpass import getpass\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service #always import this or web driver gives truble\n",
    "from selenium.webdriver.common.by import By #always import this or web driver gives truble\n",
    "from selenium.webdriver.support.select import Select #always import this\n",
    "import time\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import SessionNotCreatedException #Importing Exception\n",
    "#happen due to slow internet connection, loading ime\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "#Importing Exception\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8225be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#driver = webdriver.Chrome(ChromeDriverManager().install()) #for mac\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "855bd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa166553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b733deeff643c4a35580d1dd6ae08bbe\", element=\"d207fdd4-d185-4983-bd5b-50338392c9cd\")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_guitar=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb187e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#typed guitars\n",
    "search_guitar.click()\n",
    "search_guitar.send_keys(\"guitar\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d94125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b733deeff643c4a35580d1dd6ae08bbe\", element=\"cedcf13f-a004-4857-a332-9118234bc50d\")>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicked on search\n",
    "guitar = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div')\n",
    "guitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cbd2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6cfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.q2 In the above question, now scrape the following details of each product listed in first 3 pages of your \n",
    "#search results and save it in a data frame and csv. In case if any product has less than 3 pages in search \n",
    "#results then scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "#Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "#“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e246e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your\n",
    "search results and save it in a data frame and csv. In case if any product has less than 3 pages in search\n",
    "results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7663146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b733deeff643c4a35580d1dd6ae08bbe\", element=\"adc1ffbc-12e9-4efd-b45c-62222db52327\")>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install()) #for mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc12a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_product = input('Search Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ee8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar usind id\n",
    "search_bar = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "search_bar.send_keys(search_product)\n",
    "search_bar.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c587918",
   "metadata": {},
   "outputs": [],
   "source": [
    "  brand_name = driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/div/div/div/div/div/div[2]/div[1]/h2')\n",
    "   \n",
    "    price = driver.find_elements(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/div/div/div/div/div/div[2]/div[3]/div[1]/a/span[1]/span[2]/span[2]')\n",
    "    expected_delivery = driver.find_elements(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/div/div/div/div/div/div[2]/div[4]/div/div[1]/span[2]/span[2]')\n",
    "    product_url = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        \n",
    "data = []\n",
    "\n",
    "for i in range(len(price)):\n",
    "    temp_data = {'brand': brand_name[i].text, \n",
    "    'price': price[i].text, \n",
    "    'expected_delivery': expected_delivery[i].text,\n",
    "    'product_url': product_url[i]}\n",
    "    data.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9041dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "#www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be\n",
    "#scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "#“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "#details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "link='https://www.flipkart.com/search?q=oneplus+mobile&sid=tyy%2C4io&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_5_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_5_na_na_na&as-pos=1&as-type=RECENT&suggestionId=oneplus+mobile%7CMobiles&requestId=eb646d44-b700-4e97-824e-946728f8ccdf&as-searchtext=onepl'\n",
    "\n",
    "page = requests.get(link)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "name=soup.find('div',class_=\"_4rR01T\")\n",
    "rating=soup.find('div',class_=\"_3LWZlK\")\n",
    "specification=soup.find('div',class_=\"fMghEO\")\n",
    "\n",
    "products=[]             \n",
    "prices=[]               \n",
    "ratings=[]              \n",
    "apps = []               \n",
    "os = []                 \n",
    "hd = []                 \n",
    "sound = [] \n",
    "\n",
    "\n",
    "# for each in specification:\n",
    "#     spec=each.find_all('li',class_='rgWa7D')\n",
    "#     print(spec[0].text)\n",
    "#     print(spec[1].text)\n",
    "#     print(spec[2].text)\n",
    "#     print(spec[4].text)\n",
    "#     print(spec[5].text)\n",
    "#     print(spec[7].text)\n",
    "\n",
    "\n",
    "price=soup.find('div',class_='_30jeq3 _1_WHN1')\n",
    "\n",
    "for data in soup.findAll('div',class_='_3pLy-c row'):\n",
    "        names=data.find('div', attrs={'class':'_4rR01T'})\n",
    "        price=data.find('div', attrs={'class':'_30jeq3 _1_WHN1'})\n",
    "        rating=data.find('div', attrs={'class':'_3LWZlK'})\n",
    "        specification = data.find('div', attrs={'class':'fMghEO'})\n",
    "        \n",
    "        for each in specification:\n",
    "            col=each.find_all('li', attrs={'class':'rgWa7D'})\n",
    "            app =col[0].text\n",
    "            os_ = col[1].text\n",
    "            hd_ = col[2].text\n",
    "            sound_ = col[3].text\n",
    "            products.append(names.text) \n",
    "            prices.append(price.text) \n",
    "            apps.append(app)\n",
    "            os.append(os_) \n",
    "            hd.append(hd_) \n",
    "            sound.append(sound_) \n",
    "            ratings.append(rating.text)   \n",
    "\n",
    "\n",
    "# df=pd.DataFrame()\n",
    "# print(df.head(10))\n",
    "data = {'Product Name':products,'Supported_apps':apps,'sound_system':sound,'OS':os,\"Resolution\":hd,'Price':prices,'Rating':ratings}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df.to_csv('{0}.csv'.format('mobile_data'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bec39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21)\n",
    "#from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2664b41",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f61063ad017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m## 'th' is inside first 'tr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"th\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m## Get text from rest all 'tr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import urllib.request\n",
    "\n",
    "# user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "# headers={'User-Agent':user_agent,} \n",
    "# web = urllib.request.Request(url,None,headers)\n",
    "# s = web.read()\n",
    "\n",
    "# html = etree.HTML(s)\n",
    "\n",
    "# ## Get all 'tr'\n",
    "# tr_nodes = html.xpath('//table[@id=\"tablepress-54\"]/tr')\n",
    "\n",
    "# ## 'th' is inside first 'tr'\n",
    "# header = [i[0].text for i in tr_nodes[0].xpath(\"th\")]\n",
    "\n",
    "# ## Get text from rest all 'tr'\n",
    "# td_content = [[td.text for td in tr.xpath('td')] for tr in tr_nodes[1:]]\n",
    "\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "\n",
    "url = \"https://trak.in/india-startup-funding-investment-2015/\"\n",
    "headers={'User-Agent':user_agent,} \n",
    "\n",
    "request=urllib.request.Request(url,None,headers) #The assembled request\n",
    "response = urllib.request.urlopen(request)\n",
    "data = response.read() # The data u need\n",
    "html = etree.HTML(data)\n",
    "\n",
    "## Get all 'tr'\n",
    "tr_nodes = html.xpath('//table[@id=\"tablepress-54\"]/tr')\n",
    "\n",
    "## 'th' is inside first 'tr'\n",
    "header = [i[0].text for i in tr_nodes[0].xpath(\"th\")]\n",
    "\n",
    "## Get text from rest all 'tr'\n",
    "td_content = [[td.text for td in tr.xpath('td')] for tr in tr_nodes[1:]]\n",
    "\n",
    "td_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c9750a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape : (3511, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr. No.</th>\n",
       "      <th>Date (dd/mm/yyyy)</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/ Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>City / Location</th>\n",
       "      <th>Investors’ Name</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount (in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/05/2015</td>\n",
       "      <td>Foodpanda</td>\n",
       "      <td>Online Food Delivery</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Goldman Sachs, Rocket Internet</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/05/2015</td>\n",
       "      <td>Termsheet</td>\n",
       "      <td>Fund Raising Platform</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Anand Vijay, Nipun Dureja, Satyajit Heeralal, ...</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>100,000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>04/05/2015</td>\n",
       "      <td>Applicate</td>\n",
       "      <td>Workforce Management Software</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rishi Vasudev, Amit Gupta, Rajiv Nayan</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>550,000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>04/05/2015</td>\n",
       "      <td>World Art Community</td>\n",
       "      <td>Online Art Marketplace</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Viraj Tyagi &amp; others</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>200,000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>04/05/2015</td>\n",
       "      <td>SpoonJoy</td>\n",
       "      <td>Online Food Delivery</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>SAIF Partners</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>1,000,000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>28</td>\n",
       "      <td>26/06/2018</td>\n",
       "      <td>Sigtuple</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Data Driven Intelligence Solutions Platform</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Accel Partners, IDG Venture, Endiya Partners, ...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>19,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>29</td>\n",
       "      <td>27/06/2018</td>\n",
       "      <td>Wow Express</td>\n",
       "      <td>Technology</td>\n",
       "      <td>E-commerce Logistics Platform</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Undisclosed Existing Investors As Well As The ...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>30</td>\n",
       "      <td>28/06/2018</td>\n",
       "      <td>Front Desk AI</td>\n",
       "      <td>Technology</td>\n",
       "      <td>An AI Platform Offering Automated Customer Ser...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Speciale Invest &amp; Others</td>\n",
       "      <td>Seed/ Angel Funding</td>\n",
       "      <td>11,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>31</td>\n",
       "      <td>28/06/2018</td>\n",
       "      <td>Edureka</td>\n",
       "      <td>Ed-Tech</td>\n",
       "      <td>Online Education Platform</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Leo Capital</td>\n",
       "      <td>Seed/ Angel Funding</td>\n",
       "      <td>2,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>32</td>\n",
       "      <td>29/06/2018</td>\n",
       "      <td>Numeroseven</td>\n",
       "      <td>Technology</td>\n",
       "      <td>An Artificial Intelligence-Based Recruitment P...</td>\n",
       "      <td>Kolkatta</td>\n",
       "      <td>Shiva Gunapu &amp; Others</td>\n",
       "      <td>Seed/ Angel Funding</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3511 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sr. No. Date (dd/mm/yyyy)         Startup Name  \\\n",
       "0          1        01/05/2015            Foodpanda   \n",
       "1          2        01/05/2015            Termsheet   \n",
       "2          3        04/05/2015            Applicate   \n",
       "3          4        04/05/2015  World Art Community   \n",
       "4          5        04/05/2015             SpoonJoy   \n",
       "...      ...               ...                  ...   \n",
       "3506      28        26/06/2018             Sigtuple   \n",
       "3507      29        27/06/2018          Wow Express   \n",
       "3508      30        28/06/2018        Front Desk AI   \n",
       "3509      31        28/06/2018              Edureka   \n",
       "3510      32        29/06/2018          Numeroseven   \n",
       "\n",
       "                 Industry/ Vertical  \\\n",
       "0              Online Food Delivery   \n",
       "1             Fund Raising Platform   \n",
       "2     Workforce Management Software   \n",
       "3            Online Art Marketplace   \n",
       "4              Online Food Delivery   \n",
       "...                             ...   \n",
       "3506                     Healthcare   \n",
       "3507                     Technology   \n",
       "3508                     Technology   \n",
       "3509                        Ed-Tech   \n",
       "3510                     Technology   \n",
       "\n",
       "                                           Sub-Vertical  \\\n",
       "0                                               Gurgaon   \n",
       "1                                               Chennai   \n",
       "2                                             Bangalore   \n",
       "3                                               Gurgaon   \n",
       "4                                             Bangalore   \n",
       "...                                                 ...   \n",
       "3506       Data Driven Intelligence Solutions Platform    \n",
       "3507                      E-commerce Logistics Platform   \n",
       "3508  An AI Platform Offering Automated Customer Ser...   \n",
       "3509                          Online Education Platform   \n",
       "3510  An Artificial Intelligence-Based Recruitment P...   \n",
       "\n",
       "                                        City / Location  \\\n",
       "0                        Goldman Sachs, Rocket Internet   \n",
       "1     Anand Vijay, Nipun Dureja, Satyajit Heeralal, ...   \n",
       "2                Rishi Vasudev, Amit Gupta, Rajiv Nayan   \n",
       "3                                  Viraj Tyagi & others   \n",
       "4                                         SAIF Partners   \n",
       "...                                                 ...   \n",
       "3506                                          Bengaluru   \n",
       "3507                                             Mumbai   \n",
       "3508                                          Bengaluru   \n",
       "3509                                          Bengaluru   \n",
       "3510                                           Kolkatta   \n",
       "\n",
       "                                        Investors’ Name      Investment Type  \\\n",
       "0                                        Private Equity          100,000,000   \n",
       "1                                          Seed Funding              100,000   \n",
       "2                                          Seed Funding              550,000   \n",
       "3                                          Seed Funding              200,000   \n",
       "4                                          Seed Funding            1,000,000   \n",
       "...                                                 ...                  ...   \n",
       "3506  Accel Partners, IDG Venture, Endiya Partners, ...       Private Equity   \n",
       "3507  Undisclosed Existing Investors As Well As The ...       Private Equity   \n",
       "3508                           Speciale Invest & Others  Seed/ Angel Funding   \n",
       "3509                                        Leo Capital  Seed/ Angel Funding   \n",
       "3510                              Shiva Gunapu & Others  Seed/ Angel Funding   \n",
       "\n",
       "     Amount (in USD)  \n",
       "0           Series D  \n",
       "1                     \n",
       "2                     \n",
       "3                     \n",
       "4                     \n",
       "...              ...  \n",
       "3506      19,000,000  \n",
       "3507       4,500,000  \n",
       "3508       11,00,000  \n",
       "3509       2,000,000  \n",
       "3510             N/A  \n",
       "\n",
       "[3511 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "start_url = \"https://trak.in/india-startup-funding-investment-2015/\"\n",
    "html_response = requests.get(start_url)\n",
    "html_response.status_code # code 200 means connecition was sucessful and it is now active\n",
    "\n",
    "soup = BeautifulSoup(html_response.content, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "more_data_urls = [start_url]\n",
    "\n",
    "for h3_tag in soup.find_all(name=\"h3\"):\n",
    "    more_data_urls.append(h3_tag.find(name='a').get('href'))\n",
    "\n",
    "more_data_urls = set(more_data_urls)\n",
    "#more_data_urls\n",
    "new_row_list = []\n",
    "column_name = ['Sr. No.', 'Date (dd/mm/yyyy)', 'Startup Name', 'Industry/ Vertical', 'Sub-Vertical', 'City / Location', 'Investors’ Name', 'Investment Type', 'Amount (in USD)']\n",
    "\n",
    "urls_count = 1\n",
    "for url in more_data_urls:\n",
    "    html_response = requests.get(url)\n",
    "    html_response.status_code\n",
    "    soup = BeautifulSoup(html_response.content, 'html.parser')\n",
    "    \n",
    "    class_list = []\n",
    "    for element in soup.find_all(class_=True):\n",
    "        class_list.extend(element[\"class\"])\n",
    "    class_list = [cls for cls in class_list if 'tablepress-id-' in cls] \n",
    "    \n",
    "    if len(class_list) < 1:\n",
    "        skip_first_row = True\n",
    "        class_list.append(None)\n",
    "        for class_ in class_list:\n",
    "            tbl=soup.find(name='table') #, class_=class_)\n",
    "\n",
    "            n_rows = 0\n",
    "            for tr in tbl.find_all('tr'):\n",
    "                if skip_first_row == True:\n",
    "                    skip_first_row = False\n",
    "                    continue\n",
    "                new_row = {}\n",
    "                for col_id, td in enumerate(tr.find_all('td')):\n",
    "                    if col_id < len(column_name):\n",
    "                        new_row[column_name[col_id]] = td.text\n",
    "                if not new_row == {}:\n",
    "                    n_rows += 1\n",
    "                    new_row_list.append(new_row)\n",
    "            #print(\"class_list-old:\", class_, len(new_row_list), n_rows, url)\n",
    "    else:\n",
    "        for class_ in class_list:\n",
    "            tbl=soup.find(name='table', class_=class_)\n",
    "\n",
    "            n_rows = 0\n",
    "            for tr in tbl.find_all('tr'):\n",
    "                new_row = {}\n",
    "                for col_id, td in enumerate(tr.find_all('td')):\n",
    "                    if col_id < len(column_name):\n",
    "                        new_row[column_name[col_id]] = td.text\n",
    "                if not new_row == {}:\n",
    "                    n_rows += 1\n",
    "                    new_row_list.append(new_row)\n",
    "            #print(\"class_list-new :\", class_, len(new_row_list), n_rows, url)\n",
    "\n",
    "data = pd.DataFrame(new_row_list, columns=column_name)\n",
    "print(\"Data shape :\", data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c78e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52d946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16085691",
   "metadata": {},
   "outputs": [],
   "source": [
    "link='https://www.flipkart.com/search?q=oneplus+mobile&sid=tyy%2C4io&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_5_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_5_na_na_na&as-pos=1&as-type=RECENT&suggestionId=oneplus+mobile%7CMobiles&requestId=eb646d44-b700-4e97-824e-946728f8ccdf&as-searchtext=onepl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f11aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(link)\n",
    "soup = bs(page.content, 'html.parser')\n",
    "name=soup.find('div',class_=\"_4rR01T\")\n",
    "rating=soup.find('div',class_=\"_3LWZlK\")\n",
    "specification=soup.find('div',class_=\"fMghEO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f136bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "products=[]             \n",
    "prices=[]               \n",
    "ratings=[]              \n",
    "apps = []               \n",
    "os = []                 \n",
    "hd = []                 \n",
    "sound = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea147e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each in specification:\n",
    "#     spec=each.find_all('li',class_='rgWa7D')\n",
    "#     print(spec[0].text)\n",
    "#     print(spec[1].text)\n",
    "#     print(spec[2].text)\n",
    "#     print(spec[4].text)\n",
    "#     print(spec[5].text)\n",
    "#     print(spec[7].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69f07454",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=soup.find('div',class_='_30jeq3 _1_WHN1')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21ecc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in soup.findAll('div',class_='_3pLy-c row'):\n",
    "        names=data.find('div', attrs={'class':'_4rR01T'})\n",
    "        price=data.find('div', attrs={'class':'_30jeq3 _1_WHN1'})\n",
    "        rating=data.find('div', attrs={'class':'_3LWZlK'})\n",
    "        specification = data.find('div', attrs={'class':'fMghEO'})\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5016fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in specification:\n",
    "            col=each.find_all('li', attrs={'class':'rgWa7D'})\n",
    "            app =col[0].text\n",
    "            os_ = col[1].text\n",
    "            hd_ = col[2].text\n",
    "            sound_ = col[3].text\n",
    "            products.append(names.text) \n",
    "            prices.append(price.text) \n",
    "            apps.append(app)\n",
    "            os.append(os_) \n",
    "            hd.append(hd_) \n",
    "            sound.append(sound_) \n",
    "            ratings.append(rating.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3d41684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mproducts\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSupported_apps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mapps\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msound_system\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msound\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mos\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResolution\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mhd\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mprices\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mratings\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda 2022\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda 2022\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda 2022\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\anaconda 2022\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Product Name':products,'Supported_apps':apps,'sound_system':sound,'OS':os,\"Resolution\":hd,'Price':prices,'Rating':ratings})\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d3f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
